{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>TODO</h3> \n",
    "Fill in any place that says `YOUR CODE HERE`.\n",
    "\n",
    "<h3>Suggestions</h3>\n",
    "\n",
    "- To speed up your code, think about how certain operations can be done at the same time.\n",
    "- Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "- Double check your code does not have $\\infty$-loops, these will crash the autograder.\n",
    "\n",
    "<h3>Rules</h3>\n",
    "\n",
    "- Blank cells in the notebook are hidden tests. **Do not delete, copy, paste, or alter these cells as this will cause the tests to fail automatically**.\n",
    "- Do not create multiple python notebooks (.ipynb files).\n",
    "- Do not import any new python packages (this may cause hidden tests to fail).\n",
    "- Each cell must run for less than 5 minutes (in fact, to get all points, the entire notebook should run in under 5 minutes).\n",
    "- **Do not plagiarise!** We take violations of this very seriously. In previous years we have identified instances of plagiarism and reported them to the Senior Teaching & Learning Administrator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e682f102a98d335715990329747a9b1",
     "grade": false,
     "grade_id": "cell-22c9f752a48d4d97",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h2>Coursework 1 - Decision Trees</h2>\n",
    "\n",
    "\n",
    "<!--announcements-->\n",
    "<blockquote>\n",
    "    <center>\n",
    "    <img src=\"forest.jpg\" width=\"400px\" />\n",
    "    </center>\n",
    "      <p><cite><center>Boosting took a long time to be truly understood.<br>\n",
    "      ... cynics say we didn't see the forest for all the trees ...<br>\n",
    "      </center></cite></p>\n",
    "</blockquote>\n",
    "\n",
    "<!--announcements-->\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "654a4d51ea795467f0ecf5350bbc18a1",
     "grade": false,
     "grade_id": "cell-bcc26f0f420117c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "\n",
    "<h3>Introduction</h3>\n",
    "<p>In this assignment you will implement a decision tree algorithm and then use it for bagging and boosting. We've provided a tree structure for you with distinct leaves and nodes. Leaves have two fields, parent (another node) and prediction (a numerical value). Nodes have six fields: \n",
    "\n",
    "<ol>\n",
    "<li> <b>left</b>: node describing left subtree </li>\n",
    "<li> <b>right</b>: node describing right subtree </li>\n",
    "<li> <b>parent</b>: the parent of the current subtree. The head of the tree always has <code><b>None</b></code> as its parent. Feel free to initialize nodes with this field set to <code><b>None</b></code> so long as you set the correct parent later on. </li>\n",
    "<li> <b>cutoff_id</b>: index of feature to cut </li>\n",
    "<li> <b>cutoff_val</b>: cutoff value c (<=c : left, and >c : right)</li>\n",
    "<li> <b>prediction</b>: scalar prediction at this node </li>\n",
    "</ol>\n",
    "</p>\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ab767c2d821754994a602b0bb89254e",
     "grade": false,
     "grade_id": "cell-57d7072a148c2070",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class TreeNode(object):\n",
    "    \"\"\"Tree class.\n",
    "    \n",
    "    (You don't need to add any methods or fields here but feel\n",
    "    free to if you like. Our tests will only reference the fields\n",
    "    defined in the constructor below, so be sure to set these\n",
    "    correctly.)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, left, right, parent, cutoff_id, cutoff_val, prediction):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.parent = parent\n",
    "        self.cutoff_id = cutoff_id\n",
    "        self.cutoff_val = cutoff_val\n",
    "        self.prediction = prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "acb161f68b896c18396ede3d71d41f10",
     "grade": false,
     "grade_id": "cell-c05aa5bde6395c94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3>Implementing CART</h3>\n",
    "Before we get started let us add a few packages that you might need. We will also load a data set <a href=\"https://archive.ics.uci.edu/ml/datasets/Ionosphere\">ION</a>, which we will use as our binary test classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18f7b2887b9ec1c5a81d6863bf62b878",
     "grade": false,
     "grade_id": "cell-ba718a0ce824c1df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((281, 34), (281,), (70, 34), (70,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pylab import *\n",
    "import math\n",
    "from numpy.matlib import repmat\n",
    "import sys\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "sys.path.append('')\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "# load in some binary test data (labels are -1, +1)\n",
    "data = loadmat(\"ion.mat\")\n",
    "xTrIon  = data['xTr'].T\n",
    "yTrIon  = data['yTr'].flatten()\n",
    "xTeIon  = data['xTe'].T\n",
    "yTeIon  = data['yTe'].flatten()\n",
    "\n",
    "xTrIon.shape, yTrIon.shape, xTeIon.shape, yTeIon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cbdab1651e0c61c5e9076e59792a3a46",
     "grade": false,
     "grade_id": "cell-ba17001a88a8255d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def spiraldata(N=300):\n",
    "    r = np.linspace(1,2*np.pi,N)\n",
    "    xTr1 = np.array([np.sin(2.*r)*r, np.cos(2*r)*r]).T\n",
    "    xTr2 = np.array([np.sin(2.*r+np.pi)*r, np.cos(2*r+np.pi)*r]).T\n",
    "    xTr = np.concatenate([xTr1, xTr2], axis=0)\n",
    "    yTr = np.concatenate([np.ones(N), -1 * np.ones(N)])\n",
    "    xTr = xTr + np.random.randn(xTr.shape[0], xTr.shape[1])*0.2\n",
    "    \n",
    "    xTe = xTr[::2,:]\n",
    "    yTe = yTr[::2]\n",
    "    xTr = xTr[1::2,:]\n",
    "    yTr = yTr[1::2]\n",
    "    \n",
    "    return xTr,yTr,xTe,yTe\n",
    "\n",
    "xTrSpiral,yTrSpiral,xTeSpiral,yTeSpiral=spiraldata(150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a41f06c8edad6c0c0da0abeb403c55a",
     "grade": false,
     "grade_id": "cell-b8289ddc9797f690",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3> Efficiently implementing regression trees </h3>\n",
    "<p>First, implement the function <code>sqsplit</code> which takes as input a (weighted) data set with labels and computes the best feature and cut-value of an optimal split based on minimum squared error. The third input is a weight vector which assigns a positive weight to each training sample. The loss you should minimize is the averaged weighted squared-loss:\n",
    "$$\n",
    "\t{\\cal L}(S)=\\sum_{i \\in L} {w_{i}(y_{i} - T_{L})}^2+\\sum_{i \\in R} {w_{i}(y_{i} - T_{R})}^2.\\label{q2:loss}\n",
    "$$\n",
    "<br>\n",
    "</p>\n",
    "\n",
    "You are building a regression tree, and right now you need to choose a split for the given dataset $S=\\{(\\vec x_1,y_1),\\dots,(\\vec x_n,y_n)\\}$ (where we have continuous labels $y_i\\in{\\cal R}$).\n",
    "Suppose you split on some feature $j$ with value $c$ and partition the dataset in to two sets of indices, $L$--the set of indices on the left (i.e., $i \\in L \\Rightarrow [x_{i}]_{j} < c$)--and $R$--the set of indices on the right (i.e., $i \\in R \\Rightarrow [x_{i}]_{j} > c$). Suppose you assign every data point on the left the prediction $T_{L}$ and every data point on the right the prediction $T_{R}$. Finally, suppose that each data point $x_{i}$ has an associated weight $w_{i}$, and that the weights are normalized (i.e., $\\sum_{i} w_{i} = 1$). \n",
    "\n",
    "\n",
    "<p> First, we show that setting $T_{L}$ and $T_{R}$ to the weighted average label over their respective sets (i.e., $T_{L} = \\frac{1}{W_{L}}\\sum_{i\\in L}w_{i}y_{i}$ and $T_{R} = \\frac{1}{W_{R}}\\sum_{i\\in R}w_{i}y_{i}$) minimizes the loss $\\cal L$, where $W_{L}=\\sum_{i \\in L}w_{i}$ and $W_{R}=\\sum_{i \\in R} w_{i}$ are the total weight of the left and right side respectively.\n",
    "\n",
    "<p> We take the derivative of the loss with respect to $T_{L}$ to obtain $$\\frac{d}{dT_{L}} {\\cal L}(S) = -2\\sum_{i \\in L}w_{i}(y_i - T_L)=-2\\sum_{i\\in L}w_iy_i + 2T_{L}\\sum_{i}w_{i}$$ Setting this equal to zero and solving, we get $$2T_{L}w_{L}=2\\sum_{i \\in L}w_{i}y_{i}$$ and therefore $$T_{L} = \\frac{1}{W_{L}}\\sum_{i \\in L}w_{i}y_{i}$$ A symmetric argument holds for $T_{R}$.</p>\n",
    "\n",
    "<p> Now, imagine you are considering splitting on some feature $j$, and suppose you have already sorted the training points in the order of this feature value, so that $[x_{1}]_{j} < [x_{2}]_{j} < \\cdots < [x_{n}]_{j}$. You'd like to choose a split from among $c_{1} \\leq c_{2} \\leq \\cdots \\leq c_{n-1}$, where $c_{i}=\\frac{[x_{i}]_{j}+[x_{i+1}]_{j}}{2}$. One way to do this would be to, for each possible split $c_{k}$, decide whether each $x_{i}$ should be partitioned left or right, and compute $\\cal L$. At the end, take the split with the lowest loss. The number of data points $n$ and there are $O(n)$ splits to consider, and the proposed algorithm would require $O(n)$ per split to evaluate $\\cal L$, for a total of $O(n^2)$ time.\n",
    "\n",
    "<p> Now, suppose some split $c_{k}$ results in the data being partitioned in to $L^{(k)}$ and $R^{(k)}$. Suppose you are given the following quantities precomputed: $W_{L^{(k)}}$, $P_{L^{(k)}} = \\sum_{i \\in L} w_{i}y_{i}$, and $Q_{L^{(k)}} = \\sum_{i \\in L} w_{i}y_{i}^{2}$. Similarly, you are given $W_{R^{(k)}}$, $P_{R^{(k)}}$ and $Q_{R^{(k)}}$ Equipped with these precomputed quantities, we can compute $\\cal L$ in constant time:\n",
    "\n",
    "<p>Expand the left side of the loss to $$\\sum_{i \\in L}w_{i}y_{i}^{2} - 2\\sum_{i \\in L}w_{i}y_{i}T_{L} + \\sum_{i \\in L}w_{i}T_{L}^{2}$$. The first term is exactly $Q_{L^{(k)}}$. The second term can be written as $-2P_{L^{(k)}}\\frac{P_{L^{(k)}}}{W_{L^{(k)}}}=-2\\frac{P_{L^{(k)}}^{2}}{w_{L^{(k)}}}$. The last term can be written as $w_{L^{(k)}}\\frac{P_{L^{(k)}}^{2}}{w_{L^{(k)}}^{2}}=\\frac{P_{L^{(k)}}^{2}}{w_{L^{(k)}}}$. The second term plus the third term is therefore simply $-\\frac{P_{L^{(k)}}^{2}}{w_{L^{(k)}}}$. Therefore the whole expression can be evaluated as: $$Q_{L^{(k)}}-\\frac{P_{L^{(k)}}^{2}}{w_{L^{(k)}}}$$ Similarly, the right term is: $$Q_{R^{(k)}}-\\frac{P_{R^{(k)}}^{2}}{w_{R^{(k)}}}$$</p>\n",
    "\n",
    "<p> <b> Efficent Update Rule: </b> If all feature values are distinct, only one data point moves from $R$ to $L$ when moving from split $k$ to split $k+1$. Therefore, we simply update the values accordingly. For example, we subtract $w_{k}$ from $W_{R^{(k)}}$ and add it to $W_{L^{(k)}}$. We subtract $w_{k}y_{k}$ from $P_{R^{(k)}}$ and add it to $P_{L^{(k)}}$. We subtract $w_{k}y_{k}^{2}$ from $Q_{R^{(k)}}$ and add it to $Q_{L^{(k)}}$. Crucially, all of these updates take only constant time. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 2]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.arange(6).reshape(2,3)\n",
    "np.argwhere(x>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 2]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(np.nonzero(x>1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "z = np.array([[1, 2, 3, 4],\n",
    "         [5, 6, 7, 8],\n",
    "         [9, 10, 11, 12]])\n",
    "\n",
    "x = z.reshape(1,-1).squeeze()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = z.flatten()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65d4eb0115a5fd5f9732c09eb9bdd24c",
     "grade": false,
     "grade_id": "cell-812f4d4ed0980f9d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def sqsplit(xTr,yTr,weights=[]):\n",
    "    \"\"\"Finds the best feature, cut value, and loss value.\n",
    "    \n",
    "    Input:\n",
    "        xTr:     n x d matrix of data points\n",
    "        yTr:     n-dimensional vector of labels\n",
    "        weights: n-dimensional weight vector for data points\n",
    "    \n",
    "    Output:\n",
    "        feature:  index of the best cut's feature\n",
    "        cut:      cut-value of the best cut\n",
    "        bestloss: loss of the best cut\n",
    "    \"\"\"\n",
    "    N,D = xTr.shape\n",
    "    assert D > 0 # must have at least one dimension\n",
    "    assert N > 1 # must have at least two samples\n",
    "    if weights == []: # if no weights are passed on, assign uniform weights\n",
    "        weights = np.ones(N)\n",
    "    weights = weights/sum(weights) # Weights need to sum to one (we just normalize them)\n",
    "    bestloss = np.inf\n",
    "    feature = np.inf\n",
    "    cut = np.inf\n",
    "    \n",
    "#     print(N) #281\n",
    "#     print(D) #34\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    \n",
    "    np.seterr(divide='ignore',invalid='ignore')\n",
    "    \n",
    "    # looping through all the possible splits for any dimension\n",
    "\n",
    "    for column in range(D):\n",
    "        \n",
    "        # sorting all the points along the dimension\n",
    "        sorted_indxs = xTr[:,column] # double check this\n",
    "        sorted_indxs = list(np.argsort(sorted_indxs)) # indexes of all the rows in the current column\n",
    "        \n",
    "        # using the sorted indexes\n",
    "        xTr_sort = xTr[sorted_indxs,column]\n",
    "        yTr_sort = yTr[sorted_indxs]\n",
    "        weights_sorted = weights[sorted_indxs]\n",
    "        \n",
    "        # computing the midpoints between the pairs of points in the sorted order\n",
    "        \n",
    "        weights_sum1 = np.sum(weights_sorted[0])\n",
    "        weights_sum2 = np.sum(weights_sorted[1:])\n",
    "        T_R = np.inner(weights_sorted[1:],yTr_sort[1:])/weights_sum2 \n",
    "        T_L = np.inner(weights_sorted[0],yTr_sort[0])/weights_sum1\n",
    "            \n",
    "        C_splits = (xTr_sort[1:]+xTr_sort[:-1])/2\n",
    "#         C_splits = xTr_sort[:-1] + np.diff(xTr_sort)/2\n",
    "        \n",
    "        for c in range(0,len(C_splits)):\n",
    "            \n",
    "            split = C_splits[c]\n",
    "            r_idxs = np.transpose(np.nonzero(xTr_sort>split))\n",
    "            r_idxs = r_idxs.flatten()\n",
    "            l_idxs = np.transpose(np.nonzero(xTr_sort<=split))\n",
    "            l_idxs = l_idxs.flatten()\n",
    "            \n",
    "#             l_idxs = xTr[:,column] <= split\n",
    "#             r_idxs = ~l_idxs\n",
    "            \n",
    "            # computing the W_L,W_R,P_L,P_R,Q_L,Q_R\n",
    "            W_L = np.sum(weights[l_idxs].flatten())\n",
    "            W_R = np.sum(weights[r_idxs].flatten())\n",
    "            y_l = yTr_sort[l_idxs]\n",
    "            y_r = yTr_sort[r_idxs]\n",
    "            \n",
    "            P_L = np.sum(np.inner(weights[l_idxs],y_l))\n",
    "            P_R = np.sum(np.inner(weights[r_idxs],y_r))\n",
    "            \n",
    "            Q_L = np.sum(np.inner(weights[l_idxs],np.power(y_l,2)))\n",
    "            Q_R = np.sum(np.inner(weights[r_idxs],np.power(y_r,2)))\n",
    "        \n",
    "            Loss_L = Q_L - (np.divide(np.power(P_L,2),W_L))\n",
    "            Loss_R = Q_R - (np.divide(np.power(P_R,2),W_R))\n",
    "            \n",
    "            totalLoss = Loss_L + Loss_R\n",
    "            \n",
    "            \n",
    "            # choosing the split with the lowest loss\n",
    "            if totalLoss < bestloss:\n",
    "        \n",
    "                cut = split\n",
    "                feature = column\n",
    "                bestloss = totalLoss\n",
    "            \n",
    "    \n",
    "    return feature, cut, bestloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding the efficient update rule\n",
    "\n",
    "def sqsplit(xTr,yTr,weights=[]):\n",
    "    \"\"\"Finds the best feature, cut value, and loss value.\n",
    "    \n",
    "    Input:\n",
    "        xTr:     n x d matrix of data points\n",
    "        yTr:     n-dimensional vector of labels\n",
    "        weights: n-dimensional weight vector for data points\n",
    "    \n",
    "    Output:\n",
    "        feature:  index of the best cut's feature\n",
    "        cut:      cut-value of the best cut\n",
    "        bestloss: loss of the best cut\n",
    "    \"\"\"\n",
    "    N,D = xTr.shape\n",
    "    assert D > 0 # must have at least one dimension\n",
    "    assert N > 1 # must have at least two samples\n",
    "    if weights == []: # if no weights are passed on, assign uniform weights\n",
    "        weights = np.ones(N)\n",
    "    weights = weights/sum(weights) # Weights need to sum to one (we just normalize them)\n",
    "    bestloss = np.inf\n",
    "    feature = np.inf\n",
    "    cut = np.inf\n",
    "    \n",
    "#     print(N) #281\n",
    "#     print(D) #34\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    \n",
    "    np.seterr(divide='ignore',invalid='ignore')\n",
    "    \n",
    "    # looping through all the possible splits for any dimension\n",
    "\n",
    "    for column in range(D):\n",
    "        \n",
    "        # sorting all the points along the dimension\n",
    "        sorted_indxs = xTr[:,column] # double check this\n",
    "        sorted_indxs = list(np.argsort(sorted_indxs)) # indexes of all the rows in the current column\n",
    "        \n",
    "        # using the sorted indexes\n",
    "        xTr_sort = xTr[sorted_indxs,column]\n",
    "        yTr_sort = yTr[sorted_indxs]\n",
    "        weights_sorted = weights[sorted_indxs]\n",
    "        \n",
    "        # computing the midpoints between the pairs of points in the sorted order\n",
    "        \n",
    "        weights_sum1 = np.sum(weights_sorted[0])\n",
    "        weights_sum2 = np.sum(weights_sorted[1:])\n",
    "        T_R = np.dot(weights_sorted[1:],yTr_sort[1:])/weights_sum2 \n",
    "        T_L = np.dot(weights_sorted[0],yTr_sort[0])/weights_sum1\n",
    "            \n",
    "        C_splits = (xTr_sort[1:]+xTr_sort[:-1])/2\n",
    "#         C_splits = xTr_sort[:-1] + np.diff(xTr_sort)/2\n",
    "        \n",
    "        for c in range(0,len(C_splits)):\n",
    "            \n",
    "            split = C_splits[c]\n",
    "            r_idxs = np.transpose(np.nonzero(xTr_sort>split))\n",
    "            r_idxs = r_idxs.flatten()\n",
    "            l_idxs = np.transpose(np.nonzero(xTr_sort<=split))\n",
    "            l_idxs = l_idxs.flatten()\n",
    "            \n",
    "            # computing the W_L,W_R,P_L,P_R,Q_L,Q_R\n",
    "            w_l = weights[l_idxs]\n",
    "            w_r = weights[r_idxs]\n",
    "            W_L = np.sum(w_l.flatten())\n",
    "            W_R = np.sum(w_r.flatten())\n",
    "            y_l = yTr_sort[l_idxs]\n",
    "            y_r = yTr_sort[r_idxs]\n",
    "            \n",
    "            W_R = W_R - w_r\n",
    "            W_L = W_L + w_r\n",
    "            \n",
    "#             P_L = np.sum(np.inner(weights[l_idxs],y_l))\n",
    "#             P_R = np.sum(np.inner(weights[r_idxs],y_r))\n",
    "            P_L = np.dot(weights[l_idxs],y_l)\n",
    "            P_R = np.dot(weights[r_idxs],y_r)\n",
    "            \n",
    "            P_R = P_R - (w_r*y_r)\n",
    "            P_L = P_L + (w_r*y_r)\n",
    "\n",
    "            Q_L = np.dot(weights[l_idxs],np.power(y_l,2))\n",
    "            Q_R = np.dot(weights[r_idxs],np.power(y_r,2))\n",
    "            \n",
    "            Q_R = Q_R - (w_r*y_r**2)\n",
    "            Q_L = Q_L + (w_r*y_r**2)\n",
    "            \n",
    "\n",
    "            Loss_L = Q_L - (np.divide(np.power(P_L,2),W_L))\n",
    "            Loss_R = Q_R - (np.divide(np.power(P_R,2),W_R))\n",
    "            \n",
    "            totalLoss = Loss_L + Loss_R\n",
    "            \n",
    "            # choosing the split with the lowest loss\n",
    "            if totalLoss < bestloss:\n",
    "        \n",
    "                cut = split\n",
    "                feature = column\n",
    "                bestloss = totalLoss\n",
    "            \n",
    "    \n",
    "    return feature, cut, bestloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- loop through all possible splits for any dimension, where all possible splits are obtained by sorting all of the training points along that dimension and then computing the midpoints between any two pairs of points in the sorted order (to get all the meaningful splits between data points)\n",
    "- score each split with the squared loss (sum of the squared differences between each label and the average label, where the average label is found by )\n",
    "- pick the split with the lowest loss\n",
    "- recurse into the child nodes\n",
    "- continue until stopping criteria, every node should have a minimum number of points\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb42ab3b03a8b62728d5c24af047c1a2",
     "grade": false,
     "grade_id": "cell-2afce21057bbdb09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0.6273579597473145 seconds\n",
      "Split on feature 2 on value: 0.304\n",
      "NOTE: It should split on feature 2 on value 0.304\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "fid,cut,loss = sqsplit(xTrIon,yTrIon)\n",
    "t1 = time.time()\n",
    "print('elapsed time:',t1-t0,'seconds')\n",
    "print(\"Split on feature %i on value: %2.3f\" % (fid,cut))\n",
    "print(\"NOTE: It should split on feature 2 on value 0.304\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b450fbc9f0990f287aa976b353d5377e",
     "grade": false,
     "grade_id": "cell-30b62fba723fb04d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h2>Testing Your Code</h2>\n",
    "\n",
    "<p>As your code will be tested by an autograder, <b>we highly recommend you test all of the code you implement</b> to make sure it works as you expect in both normal and abnormal use-cases. Below shows an example test for the sqsplit function. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4dd36f98917cc93423b58c1ca4176cf0",
     "grade": false,
     "grade_id": "cell-7e0a19890691b587",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function sqsplit correctly calculates bestloss on xor1/yor1 example: True\n"
     ]
    }
   ],
   "source": [
    "# an example test\n",
    "xor1 = np.array([[1, 1, 1, 1, 0, 0, 0, 0],\n",
    "                 [1, 1, 0, 0, 1, 1, 0, 0],\n",
    "                 [1, 0, 1, 0, 1, 0, 1, 0]]).T\n",
    "yor1 = np.array( [1, 0, 0, 1, 0, 1, 1, 0])\n",
    "b = np.isclose(sqsplit(xor1,yor1)[2], .25)\n",
    "print('Function sqsplit correctly calculates bestloss on xor1/yor1 example: ' + str(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b4511a8fa20e6617f27ab789e2dc3c9",
     "grade": true,
     "grade_id": "sqsplit_test1",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b820a08e2b8919033e1902f729525fea",
     "grade": false,
     "grade_id": "cell-747473d0185a7d75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Cart tree:</b><p>Implement the function <code>cart</code> which returns a regression tree based on the minimum squared loss splitting rule. The function takes training data, test data, a maximum depth, and the weigh of each training example. Maximum depth and weight are optional arguments. If they are not provided you should make maximum depth infinity and equally weight each example. You should use the function <code>sqsplit</code> to make your splits.</p>\n",
    "\n",
    "<p>Use the provided <code>TreeNode</code> class to represent your tree. Note that the nature of CART trees implies that every node has exactly 0 or 2 children.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5527a56a8e4ded73266026512d9b835d",
     "grade": false,
     "grade_id": "cell-3d1c561cd988c041",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cart(xTr,yTr,depth=np.inf,weights=None):\n",
    "    \"\"\"Builds a CART tree.\n",
    "    \n",
    "    The maximum tree depth is defined by \"maxdepth\" (maxdepth=2 means one split).\n",
    "    Each example can be weighted with \"weights\".\n",
    "\n",
    "    Args:\n",
    "        xTr:      n x d matrix of data\n",
    "        yTr:      n-dimensional vector\n",
    "        maxdepth: maximum tree depth\n",
    "        weights:  n-dimensional weight vector for data points\n",
    "\n",
    "    Returns:\n",
    "        tree: root of decision tree\n",
    "    \"\"\"\n",
    "    n,d = xTr.shape  # samples, features\n",
    "    if weights is None:\n",
    "        w = np.ones(n) / float(n)\n",
    "    else:\n",
    "        w = weights\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "    \n",
    "        \n",
    "    # initialising a tree \n",
    "    tree = TreeNode(left=None,right=None,parent=None,cutoff_id=None,cutoff_val=None,prediction=None)\n",
    "\n",
    "    # a tree can be split if the number of samples is 2 or more\n",
    "    if (depth < 2) or (n < 2):\n",
    "        tree.prediction = np.divide(1,np.sum(w)*np.sum(w*yTr))\n",
    "        \n",
    "        return tree\n",
    "    \n",
    "    else:\n",
    "        # feature, cut, bestloss = sqsplit(xTr,yTr)\n",
    "        split = sqsplit(xTr,yTr,w)\n",
    "        feature = split[0]\n",
    "        cut = split[1]\n",
    "        bestloss = split[2]\n",
    "        if feature == -1:\n",
    "            return tree\n",
    "        \n",
    "\n",
    "    r_indxs = xTr[:,feature]>cut\n",
    "    r_x = xTr[r_indxs]\n",
    "    r_y = yTr[r_indxs]\n",
    "    r_w = w[r_indxs]\n",
    "\n",
    "    l_indxs = xTr[:,feature]<=cut\n",
    "    l_x = xTr[l_indxs]\n",
    "    l_y = yTr[l_indxs]\n",
    "    l_w = w[l_indxs]\n",
    "    \n",
    "    tree.prediction = np.divide(1,np.sum(w)*np.sum(w*yTr))\n",
    "    tree.cutoff_id = feature\n",
    "    tree.cutoff_val = cut\n",
    "    \n",
    "    # using recursion\n",
    "    tree.left = cart(l_x,l_y,depth-1,l_w)\n",
    "    if tree.left != None:\n",
    "        tree.left.parent = tree\n",
    "        \n",
    "    tree.right = cart(r_x,r_y,depth-1,r_w) \n",
    "    if tree.right != None:\n",
    "        tree.right.parent = tree\n",
    "        \n",
    "    return tree \n",
    "        \n",
    "    \n",
    "#     if feature != np.inf:\n",
    "#         x_r = []\n",
    "#         y_r = []\n",
    "#         weigths_r = []\n",
    "#         x_l = []\n",
    "#         y_l = []\n",
    "#         weights_l = []\n",
    "        \n",
    "#         if sample in range(n):\n",
    "            \n",
    "        \n",
    "\n",
    "        \n",
    "#         tree = TreeNode(left,right,feature,cut,prediction)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     return tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd version of cart\n",
    "\n",
    "def cart(xTr,yTr,depth=np.inf,weights=None):\n",
    "    \"\"\"Builds a CART tree.\n",
    "    \n",
    "    The maximum tree depth is defined by \"maxdepth\" (maxdepth=2 means one split).\n",
    "    Each example can be weighted with \"weights\".\n",
    "\n",
    "    Args:\n",
    "        xTr:      n x d matrix of data\n",
    "        yTr:      n-dimensional vector\n",
    "        maxdepth: maximum tree depth\n",
    "        weights:  n-dimensional weight vector for data points\n",
    "\n",
    "    Returns:\n",
    "        tree: root of decision tree\n",
    "    \"\"\"\n",
    "    n,d = xTr.shape\n",
    "    if weights is None:\n",
    "        w = np.ones(n) / float(n)\n",
    "    else:\n",
    "        w = weights\n",
    "    \n",
    "    root = None\n",
    "    \n",
    "    if depth==1 or n==1:\n",
    "        root = TreeNode(None, None, None, None, None, np.mean(yTr))\n",
    "    \n",
    "    else:\n",
    "        split = sqsplit(xTr,yTr,w)\n",
    "        feature = split[0]\n",
    "        cut = split[1]\n",
    "        bestloss = split[2]\n",
    "    \n",
    "        if feature != np.inf:\n",
    "            x_r = []\n",
    "            y_r = []\n",
    "            weights_r = []\n",
    "\n",
    "            x_l = []\n",
    "            y_l = []\n",
    "            weights_l = []\n",
    "\n",
    "            for sample in range(n):\n",
    "\n",
    "                s_point = xTr[sample]\n",
    "\n",
    "                if s_point[feature] > cut:\n",
    "                    x_r.append(xTr[sample])\n",
    "                    weights_r.append(w[sample])\n",
    "                    y_r.append(yTr[sample])\n",
    "                else:\n",
    "                    x_l.append(xTr[sample])\n",
    "                    weights_l.append(w[sample])\n",
    "                    y_l.append(yTr[sample])\n",
    "\n",
    "\n",
    "            if (len(x_l)==0) or (len(x_r)==0):\n",
    "                root = TreeNode(None, None, None, None, None,np.sum(yTr)/n)\n",
    "            else:\n",
    "                x_r = np.array(x_r)\n",
    "                y_r = np.array(y_r)\n",
    "                weights_r = np.array(weights_r)\n",
    "                x_l = np.array(x_l)\n",
    "                y_l = np.array(y_l)\n",
    "                weights_l = np.array(weights_l)\n",
    "\n",
    "                # using recursion \n",
    "                if  depth != np.inf:\n",
    "                    cart_r = cart(x_r,y_r,depth-1,weights_r)\n",
    "                    cart_l = cart(x_l,y_l,depth-1,weights_l)\n",
    "                else:\n",
    "                    cart_r = cart(x_r,y_r,np.inf,weights_r)\n",
    "                    cart_l = cart(x_l,y_l,np.inf,weights_l)\n",
    "\n",
    "\n",
    "                root = TreeNode(None, None, None,0,0,yTr)\n",
    "\n",
    "                root.right = cart_r\n",
    "                root.left = cart_l\n",
    "                root.cutoff_id = feature\n",
    "                root.cutoff_val = cut\n",
    "                root.prediction = np.divide((cart_r.prediction + cart_l.prediction),2)\n",
    "                cart_r.parent = root\n",
    "                cart_l.parent = root\n",
    "            \n",
    "    return tree\n",
    "            \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart(xTr,yTr,depth=np.inf,weights=None):\n",
    "    \"\"\"Builds a CART tree.\n",
    "    \n",
    "    The maximum tree depth is defined by \"maxdepth\" (maxdepth=2 means one split).\n",
    "    Each example can be weighted with \"weights\".\n",
    "​\n",
    "    Args:\n",
    "        xTr:      n x d matrix of data\n",
    "        yTr:      n-dimensional vector\n",
    "​\n",
    "    Returns:\n",
    "        tree: root of decision tree\n",
    "    \"\"\"\n",
    "    n,d = xTr.shape\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    if weights is None:\n",
    "        w = np.ones(n) / float(n)\n",
    "    else:\n",
    "        w = weights\n",
    "    head = TreeNode(None,None,None,None,None,None)\n",
    "    #base case I\n",
    "    if depth <= 1 or n < 2:# no cut\n",
    "        head.prediction = 1.0 / np.sum(w) * np.sum(w * yTr)\n",
    "        return head\n",
    "        \n",
    "    # recursion         \n",
    "    else:\n",
    "​\n",
    "        feature, cut, bestloss = sqsplit(xTr,yTr,w)\n",
    "        if feature == -1:\n",
    "            return head\n",
    "​\n",
    "        Lindex = xTr[:, feature] <= cut\n",
    "        Rindex = xTr[:, feature] > cut\n",
    "                     \n",
    "        xL = xTr[Lindex]\n",
    "        yL = yTr[Lindex]\n",
    "        wL = w[Lindex]\n",
    "                     \n",
    "        xR = xTr[Rindex]\n",
    "        yR = yTr[Rindex]\n",
    "        wR = w[Rindex]\n",
    "        \n",
    "​\n",
    "        head.prediction = 1.0 / np.sum(w) * np.sum(w * yTr)\n",
    "                \n",
    "        \n",
    "        head.cutoff_id = feature\n",
    "        head.cutoff_val = cut\n",
    "        \n",
    "        head.left = cart(xL, yL, depth - 1,wL)\n",
    "        \n",
    "        if head.left != None:\n",
    "            head.left.parent = head\n",
    "            \n",
    "        head.right = cart(xR, yR, depth - 1,wR)\n",
    "        if head.right != None:\n",
    "            head.right.parent = head\n",
    "        return head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pernodeeval(root, pnt):\n",
    "    if(root.left==None and root.right==None):\n",
    "        return root.prediction\n",
    "    else:\n",
    "        if(pnt[root.cutoff_id]<=root.cutoff_val):\n",
    "            return pernodeeval(root.left, pnt)\n",
    "        else:\n",
    "            return pernodeeval(root.right, pnt)\n",
    "        \n",
    "def evaltree(root,xTe):\n",
    "    \"\"\"Evaluates xTe using decision tree root.\n",
    "    \n",
    "    Input:\n",
    "        root: TreeNode decision tree\n",
    "        xTe:  n x d matrix of data points\n",
    "    \n",
    "    Output:\n",
    "        pred: n-dimensional vector of predictions\n",
    "    \"\"\"\n",
    "    assert root is not None\n",
    "    \n",
    "    #todo\n",
    "    n,d = xTe.shape\n",
    "    pred = np.zeros(n)\n",
    "    for i in range(0, n):\n",
    "        pred[i]=pernodeeval(root,xTe[i])\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second version of evaltree\n",
    "\n",
    "raise NotImplementedError()\n",
    "\n",
    "def evaltree(root,xTe):\n",
    "    \"\"\"Evaluates xTe using decision tree root.\n",
    "    \n",
    "    Input:\n",
    "        root: TreeNode decision tree\n",
    "        xTe:  n x d matrix of data points\n",
    "    \n",
    "    Output:\n",
    "        pred: n-dimensional vector of predictions\n",
    "    \"\"\"\n",
    "    assert root is not None\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third version of evaltree\n",
    "\n",
    "def calc_prediction()\n",
    "    \n",
    "\n",
    "\n",
    "def evaltree(root,xTe):\n",
    "    \"\"\"Evaluates xTe using decision tree root.\n",
    "    \n",
    "    Input:\n",
    "        root: TreeNode decision tree\n",
    "        xTe:  n x d matrix of data points\n",
    "    \n",
    "    Output:\n",
    "        pred: n-dimensional vector of predictions\n",
    "    \"\"\"\n",
    "    assert root is not None\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "    samples,features = xTe.shape\n",
    "\n",
    "\n",
    "    assert (root.right!=None) and (root.left!=None)\n",
    "    \n",
    "    right = xTe[:,root.feature] > root.cut\n",
    "    left = xTe[:,root.feature] <= root.cut\n",
    "    \n",
    "    bools = np.ones(samples) == 1\n",
    "    right_i = right & bools\n",
    "    left_i = left & bools\n",
    "    \n",
    "    rt_r = root.right\n",
    "    rt_l = root.left\n",
    "    rt_rr = rt_r.right\n",
    "    rt_rl = rt_r.left\n",
    "    rt_ll = rt_l.left.left\n",
    "    rt_lr = rt_l.left.right\n",
    "    \n",
    "    predictions = np.zeros(samples)\n",
    "    \n",
    "    if (rt_rr!=None) and (rt_rl!=None): \n",
    "#         prediction = evaltree(rt_r,xTe,right_i)\n",
    "#         pred_list.insert(prediction,idx)\n",
    "        predictions[right_i]=evaltree(rt_r.prediction)\n",
    "    else:\n",
    "        predictions[right_i]=rt_r.prediction\n",
    "    \n",
    "    if (rt_ll!=None) and (rt_lr!=None): \n",
    "        predictions[left_i]=evaltree(rt_l.prediction)\n",
    "    else:\n",
    "        predictions[left_i]=rt_l.prediction\n",
    "    \n",
    "    pred =  predictions[bools]\n",
    "    \n",
    "    return pred\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c50f31520ca9a59e7d68de15ab80e3f6",
     "grade": false,
     "grade_id": "cell-c0bad89ae412f3d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<p>Implement the function <code>evaltree</code>, which evaluates a decision tree on a given test data set.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "719328b34225f0f9ccf4f094ad969f1c",
     "grade": false,
     "grade_id": "cell-3c4bbc7ba9f357d5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "def evaltree(root,xTe):\n",
    "    \"\"\"Evaluates xTe using decision tree root.\n",
    "    \n",
    "    Input:\n",
    "        root: TreeNode decision tree\n",
    "        xTe:  n x d matrix of data points\n",
    "    \n",
    "    Output:\n",
    "        pred: n-dimensional vector of predictions\n",
    "    \"\"\"\n",
    "    assert root is not None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rec_evaltree(root,idx):\n",
    "    \n",
    "\n",
    "\n",
    "def evaltree(root, xTe, idx=[]):\n",
    "    \"\"\"Evaluating xTe using decision tree root.\n",
    "    Input:\n",
    "        root: TreeNode decision tree\n",
    "        xTe:  n x d matrix of data points\n",
    "    Output:\n",
    "        pred: n-dimensional vector of predictions\n",
    "    \"\"\"\n",
    "    assert root is not None\n",
    "    n = xTe.shape[0]\n",
    "    pred = np.zeros(n)\n",
    "    # TODO:\n",
    "    if len(idx) == 0: idx = np.ones(n) == 1\n",
    "    if root.left is None and root.right is None:\n",
    "        return np.ones(sum(idx)) * root.prediction\n",
    "    assert root.left is not None and root.right is not None\n",
    "    feature, cutoff = root.feature, root.cut\n",
    "    idxL = idx & (xTe[:, feature] <= cutoff)\n",
    "    if root.left.left == None and root.left.right == None:\n",
    "        pred[idxL] = root.left.prediction\n",
    "    else:\n",
    "        pred[idxL] = evaltree(root.left, xTe, idxL)\n",
    "    idxR = idx & (xTe[:, feature] > cutoff)\n",
    "    if root.right.left == None and root.right.right == None:\n",
    "        pred[idxR] = root.right.prediction\n",
    "    else:\n",
    "        pred[idxR] = evaltree(root.right, xTe, idxR)\n",
    "    return pred[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 4 of cart tree\n",
    "\n",
    "def evaltree(root,xTe):\n",
    "    \"\"\"Evaluates xTe using decision tree root.\n",
    "    \n",
    "    Input:\n",
    "        root: TreeNode decision tree\n",
    "        xTe:  n x d matrix of data points\n",
    "    \n",
    "    Output:\n",
    "        pred: n-dimensional vector of predictions\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    pred = []\n",
    "    '''\n",
    "    for i in rsnge N\n",
    "        XTE[I]\n",
    "    root has a cut\n",
    "    while loop\n",
    "        xte  000110\n",
    "        cut  - 0.5\n",
    "        f= 2.\n",
    "        root .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b51b79f63b52b2265e0abaff96f6598",
     "grade": false,
     "grade_id": "cell-59837ef34f3d8973",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<p>In the below test you should see an output very similar to the following: \n",
    "\n",
    "<code>elapsed time: 0.65 seconds\n",
    "Training RMSE : 0.00\n",
    "Testing  RMSE : 0.74\n",
    "</code>\n",
    "\n",
    "(<code>elapsed time</code> will be slightly different)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a05362b379de72ec25fb6e0fc7efa13",
     "grade": false,
     "grade_id": "cell-49d4579bb2429635",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12736/3328055093.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxTrIon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myTrIon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtr_err\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaltree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxTrIon\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0myTrIon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12736/830656787.py\u001b[0m in \u001b[0;36mcart\u001b[1;34m(xTr, yTr, depth, weights)\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[0mcart_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12736/830656787.py\u001b[0m in \u001b[0;36mcart\u001b[1;34m(xTr, yTr, depth, weights)\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[0mcart_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12736/830656787.py\u001b[0m in \u001b[0;36mcart\u001b[1;34m(xTr, yTr, depth, weights)\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[0mcart_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12736/830656787.py\u001b[0m in \u001b[0;36mcart\u001b[1;34m(xTr, yTr, depth, weights)\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[0mcart_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12736/830656787.py\u001b[0m in \u001b[0;36mcart\u001b[1;34m(xTr, yTr, depth, weights)\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[0mcart_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12736/830656787.py\u001b[0m in \u001b[0;36mcart\u001b[1;34m(xTr, yTr, depth, weights)\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[0mcart_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12736/830656787.py\u001b[0m in \u001b[0;36mcart\u001b[1;34m(xTr, yTr, depth, weights)\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[0mcart_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12736/830656787.py\u001b[0m in \u001b[0;36mcart\u001b[1;34m(xTr, yTr, depth, weights)\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[0mcart_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12736/830656787.py\u001b[0m in \u001b[0;36mcart\u001b[1;34m(xTr, yTr, depth, weights)\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[0mcart_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12736/830656787.py\u001b[0m in \u001b[0;36mcart\u001b[1;34m(xTr, yTr, depth, weights)\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[0mcart_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12736/830656787.py\u001b[0m in \u001b[0;36mcart\u001b[1;34m(xTr, yTr, depth, weights)\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[0mcart_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12736/830656787.py\u001b[0m in \u001b[0;36mcart\u001b[1;34m(xTr, yTr, depth, weights)\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[0mcart_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12736/830656787.py\u001b[0m in \u001b[0;36mcart\u001b[1;34m(xTr, yTr, depth, weights)\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[0mcart_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12736/830656787.py\u001b[0m in \u001b[0;36mcart\u001b[1;34m(xTr, yTr, depth, weights)\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[0mcart_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12736/830656787.py\u001b[0m in \u001b[0;36mcart\u001b[1;34m(xTr, yTr, depth, weights)\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[0mcart_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12736/830656787.py\u001b[0m in \u001b[0;36mcart\u001b[1;34m(xTr, yTr, depth, weights)\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[0mcart_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12736/830656787.py\u001b[0m in \u001b[0;36mcart\u001b[1;34m(xTr, yTr, depth, weights)\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[0mcart_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                     \u001b[0mcart_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12736/830656787.py\u001b[0m in \u001b[0;36mcart\u001b[1;34m(xTr, yTr, depth, weights)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0mcart_l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tree' is not defined"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "root = cart(xTrIon, yTrIon)\n",
    "t1 = time.time()\n",
    "\n",
    "tr_err   = np.mean((evaltree(root,xTrIon) - yTrIon)**2)\n",
    "te_err   = np.mean((evaltree(root,xTeIon) - yTeIon)**2)\n",
    "\n",
    "print(\"elapsed time: %.2f seconds\" % (t1-t0))\n",
    "print(\"Training RMSE : %.2f\" % tr_err)\n",
    "print(\"Testing  RMSE : %.2f\" % te_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1581db60d6b0770249b79ae4bc8e640c",
     "grade": false,
     "grade_id": "cell-0a4ad9b8acc2afff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<p>The following code defines a function <code>visclassifier()</code>, which plots the decision boundary of a classifier in 2 dimensions. Execute the following code to see what the decision boundary of your tree looks like on the ion data set. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a2ff788e00650728f3e780e8ba4db31",
     "grade": false,
     "grade_id": "cell-fc29736055ce2744",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def visclassifier(fun,xTr,yTr,w=[],b=0):\n",
    "    \"\"\"\n",
    "    visualize decision boundary\n",
    "    Define the symbols and colors we'll use in the plots later\n",
    "    \"\"\"\n",
    "\n",
    "    yTr = np.array(yTr).flatten()\n",
    "    w = np.array(w).flatten()\n",
    "\n",
    "    symbols = [\"ko\",\"kx\"]\n",
    "    marker_symbols = ['o', 'x']\n",
    "    mycolors = [[0.5, 0.5, 1], [1, 0.5, 0.5]]\n",
    "    # get the unique values from labels array\n",
    "    classvals = np.unique(yTr)\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    # return 300 evenly spaced numbers over this interval\n",
    "    res=300\n",
    "    xrange = np.linspace(min(xTr[:, 0]), max(xTr[:, 0]),res)\n",
    "    yrange = np.linspace(min(xTr[:, 1]), max(xTr[:, 1]),res)\n",
    "    \n",
    "    # repeat this matrix 300 times for both axes\n",
    "    pixelX = repmat(xrange, res, 1)\n",
    "    pixelY = repmat(yrange, res, 1).T\n",
    "\n",
    "    \n",
    "    xTe = np.array([pixelX.flatten(), pixelY.flatten()]).T\n",
    "\n",
    "    # test all of these points on the grid\n",
    "    testpreds = fun(xTe)\n",
    "    \n",
    "    # reshape it back together to make our grid\n",
    "    Z = testpreds.reshape(res, res)\n",
    "    # Z[0,0] = 1 # optional: scale the colors correctly\n",
    "    \n",
    "    # fill in the contours for these predictions\n",
    "    plt.contourf(pixelX, pixelY, np.sign(Z), colors=mycolors)\n",
    "\n",
    "    # creates x's and o's for training set\n",
    "    for idx, c in enumerate(classvals):\n",
    "        plt.scatter(xTr[yTr == c,0],\n",
    "            xTr[yTr == c,1],\n",
    "            marker=marker_symbols[idx],\n",
    "            color='k'\n",
    "            )\n",
    "    \n",
    "    if w != []:\n",
    "        alpha = -1 * b / (w ** 2).sum()\n",
    "        plt.quiver(w[0] * alpha, w[1] * alpha,\n",
    "            w[0], w[1], linewidth=2, color=[0,1,0])\n",
    "\n",
    "    plt.axis('tight')\n",
    "    # shows figure and blocks\n",
    "    plt.show()\n",
    "\n",
    "tree=cart(xTrSpiral,yTrSpiral) # compute tree on training data \n",
    "visclassifier(lambda X:evaltree(tree,X),xTrSpiral,yTrSpiral)\n",
    "print(\"Training error: %.4f\" % np.mean(np.sign(evaltree(tree,xTrSpiral)) != yTrSpiral))\n",
    "print(\"Testing error:  %.4f\" % np.mean(np.sign(evaltree(tree,xTeSpiral)) != yTeSpiral))\n",
    "print(\"NOTE: You should get something similar to:\")\n",
    "print(\"Training error: 0.0000\")\n",
    "print(\"Testing error:  0.0467 (may be slightly different)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "792f83854719ab0aee42d35b1724d363",
     "grade": false,
     "grade_id": "cell-0023f5ab24eedcf8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def onclick_cart(event):\n",
    "    \"\"\"\n",
    "    Visualize cart, including new point\n",
    "    \"\"\"\n",
    "    global xTraining,labels\n",
    "    # create position vector for new point\n",
    "    pos=np.array([[event.xdata,event.ydata]]) \n",
    "    if event.key == 'shift': # add positive point\n",
    "        color='or'\n",
    "        label=1\n",
    "    else: # add negative point\n",
    "        color='ob'\n",
    "        label=-1    \n",
    "    xTraining = np.concatenate((xTraining,pos), axis = 0)\n",
    "    labels.append(label);\n",
    "    marker_symbols = ['o', 'x']\n",
    "    classvals = np.unique(labels)\n",
    "        \n",
    "    mycolors = [[0.5, 0.5, 1], [1, 0.5, 0.5]]\n",
    "    \n",
    "    # return 300 evenly spaced numbers over this interval\n",
    "    res=300\n",
    "    xrange = np.linspace(0, 1,res)\n",
    "    yrange = np.linspace(0, 1,res)\n",
    "\n",
    "    \n",
    "    # repeat this matrix 300 times for both axes\n",
    "    pixelX = repmat(xrange, res, 1)\n",
    "    pixelY = repmat(yrange, res, 1).T\n",
    "\n",
    "    xTe = np.array([pixelX.flatten(), pixelY.flatten()]).T\n",
    "\n",
    "    # get decision tree\n",
    "    tree=cart(xTraining,np.array(labels).flatten())\n",
    "    fun = lambda X:evaltree(tree,X)\n",
    "    # test all of these points on the grid\n",
    "    testpreds = fun(xTe)\n",
    "    \n",
    "    # reshape it back together to make our grid\n",
    "    Z = testpreds.reshape(res, res)\n",
    "    # Z[0,0] = 1 # optional: scale the colors correctly\n",
    "    \n",
    "    plt.cla()    \n",
    "    plt.xlim((0,1))\n",
    "    plt.ylim((0,1))\n",
    "    # fill in the contours for these predictions\n",
    "    plt.contourf(pixelX, pixelY, np.sign(Z), colors=mycolors)\n",
    "    \n",
    "    for idx, c in enumerate(classvals):\n",
    "        plt.scatter(xTraining[labels == c,0],\n",
    "            xTraining[labels == c,1],\n",
    "            marker=marker_symbols[idx],\n",
    "            color='k'\n",
    "            )\n",
    "    plt.show()\n",
    "    \n",
    "        \n",
    "xTraining= np.array([[5,6]])\n",
    "labels = [1]\n",
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick_cart)\n",
    "plt.title('Use shift-click to add negative points.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "12fdfb699ed6db478e2a2ec6d31496fb",
     "grade": false,
     "grade_id": "cell-9f203d5c35d17423",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h2>Random Forests</h2>\n",
    "<p>CART trees are known to be high variance classifiers\n",
    "(if trained to full depth).\n",
    "An effective way to prevent overfitting is to use <b>Bagging</b>.\n",
    "Implement the function <code>forest</code>,\n",
    "which builds a forest of regression trees.\n",
    "Each tree should be built using training data\n",
    "drawn by randomly sampling $n$ examples\n",
    "from the training data with replacement.\n",
    "Do not randomly sample features.\n",
    "The function should output a list of trees.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50849f154123b8b15f270deb963a2417",
     "grade": false,
     "grade_id": "cell-f8a92665c255c104",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def forest(xTr, yTr, m, maxdepth=np.inf):\n",
    "    \"\"\"Creates a random forest.\n",
    "    \n",
    "    Input:\n",
    "        xTr:      n x d matrix of data points\n",
    "        yTr:      n-dimensional vector of labels\n",
    "        m:        number of trees in the forest\n",
    "        maxdepth: maximum depth of tree\n",
    "        \n",
    "    Output:\n",
    "        trees: list of TreeNode decision trees of length m\n",
    "    \"\"\"\n",
    "    \n",
    "    n, d = xTr.shape\n",
    "    trees = []\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "579342c0bf08182b3eacbb8d589e525b",
     "grade": false,
     "grade_id": "cell-01fb3000253d168b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<p>Now implement the function <code>evalforest</code>, which should take as input a set of $m$ trees, a set of $n$ test inputs, and an $m$ dimensional weight vector. Each tree should be weighted by the corresponding weight. (For random forests you can define the weights to be $\\frac{1}{m}$ for all trees.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "251269c6ed314b7900529002cf2e74de",
     "grade": false,
     "grade_id": "cell-fb4677da9cfa542a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def evalforest(trees, X, alphas=None):\n",
    "    \"\"\"Evaluates X using trees.\n",
    "    \n",
    "    Input:\n",
    "        trees:  list of TreeNode decision trees of length m\n",
    "        X:      n x d matrix of data points\n",
    "        alphas: m-dimensional weight vector\n",
    "        \n",
    "    Output:\n",
    "        pred: n-dimensional vector of predictions\n",
    "    \"\"\"\n",
    "    m = len(trees)\n",
    "    n,d = X.shape\n",
    "    if alphas is None:\n",
    "        alphas = np.ones(m) / len(trees)\n",
    "            \n",
    "    pred = np.zeros(n)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d9944d659e149ec4172a1fcf90c0772",
     "grade": false,
     "grade_id": "cell-f4b15aac0a3f4d1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<p>The following script visualizes the decision boundary of a random forest ensemble.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6d5544c1b35f9c44c1489807e90faf4",
     "grade": false,
     "grade_id": "cell-fce6ab17683fff14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "trees=forest(xTrSpiral,yTrSpiral,30) # compute tree on training data \n",
    "visclassifier(lambda X:evalforest(trees,X),xTrSpiral,yTrSpiral)\n",
    "print(\"Training error: %.4f\" % np.mean(np.sign(evaltree(tree,xTrSpiral)) != yTrSpiral))\n",
    "print(\"Testing error:  %.4f\" % np.mean(np.sign(evaltree(tree,xTeSpiral)) != yTeSpiral))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "240ad5b0621527e90f5f215d0e1b2506",
     "grade": false,
     "grade_id": "cell-aba5f94293c2e524",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<p>The following script evaluates the test and training error of a random forest ensemble as we vary the number of trees.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0738c12966adbfd61677c854a83ed7c7",
     "grade": false,
     "grade_id": "cell-a3d95218b61c5dfe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "M=20 # max number of trees\n",
    "err_trB=[]\n",
    "err_teB=[]\n",
    "alltrees=forest(xTrIon,yTrIon,M)\n",
    "for i in range(M):\n",
    "    trees=alltrees[:i+1]\n",
    "    trErr = np.mean(np.sign(evalforest(trees,xTrIon)) != yTrIon)\n",
    "    teErr = np.mean(np.sign(evalforest(trees,xTeIon)) != yTeIon)\n",
    "    err_trB.append(trErr)\n",
    "    err_teB.append(teErr)\n",
    "    print(\"[%d]training err = %.4f\\ttesting err = %.4f\" % (i,trErr, teErr))\n",
    "\n",
    "plt.figure()\n",
    "line_tr, = plt.plot(range(M),err_trB,label=\"Training Error\")\n",
    "line_te, = plt.plot(range(M),err_teB,label=\"Testing error\")\n",
    "plt.title(\"Random Forest\")\n",
    "plt.legend(handles=[line_tr, line_te])\n",
    "plt.xlabel(\"# of trees\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.show()\n",
    "# Your training error should converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b4d3902787aa6127913458b110f9aab",
     "grade": false,
     "grade_id": "cell-40b0e860bbf15397",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def onclick_forest(event):\n",
    "    \"\"\"\n",
    "    Visualize forest, including new point\n",
    "    \"\"\"\n",
    "    global xTrain,yTrain,w,b,M\n",
    "    # create position vector for new point\n",
    "    pos=np.array([[event.xdata,event.ydata]]) \n",
    "    if event.key == 'shift': # add positive point\n",
    "        color='or'\n",
    "        label=1\n",
    "    else: # add negative point\n",
    "        color='ob'\n",
    "        label=-1    \n",
    "    xTrain = np.concatenate((xTrain,pos), axis = 0)\n",
    "    yTrain = np.append(yTrain, label)\n",
    "    marker_symbols = ['o', 'x']\n",
    "    classvals = np.unique(yTrain)\n",
    "        \n",
    "    w = np.array(w).flatten()\n",
    "    \n",
    "    mycolors = [[0.5, 0.5, 1], [1, 0.5, 0.5]]\n",
    "    \n",
    "    # return 300 evenly spaced numbers over this interval\n",
    "    res=300\n",
    "    xrange = np.linspace(0, 1,res)\n",
    "    yrange = np.linspace(0, 1,res)\n",
    "    \n",
    "    # repeat this matrix 300 times for both axes\n",
    "    pixelX = repmat(xrange, res, 1)\n",
    "    pixelY = repmat(yrange, res, 1).T\n",
    "\n",
    "    xTe = np.array([pixelX.flatten(), pixelY.flatten()]).T\n",
    "\n",
    "    # get forest\n",
    "    trees=forest(xTrain,yTrain,M)\n",
    "    fun = lambda X:evalforest(trees,X)\n",
    "    # test all of these points on the grid\n",
    "    testpreds = fun(xTe)\n",
    "    \n",
    "    # reshape it back together to make our grid\n",
    "    Z = testpreds.reshape(res, res)\n",
    "    # Z[0,0] = 1 # optional: scale the colors correctly\n",
    "    \n",
    "    plt.cla()    \n",
    "    plt.xlim((0,1))\n",
    "    plt.ylim((0,1))\n",
    "    # fill in the contours for these predictions\n",
    "    plt.contourf(pixelX, pixelY, np.sign(Z), colors=mycolors)\n",
    "    \n",
    "    for idx, c in enumerate(classvals):\n",
    "        plt.scatter(xTrain[yTrain == c,0],\n",
    "            xTrain[yTrain == c,1],\n",
    "            marker=marker_symbols[idx],\n",
    "            color='k'\n",
    "            )\n",
    "    plt.show()\n",
    "    \n",
    "        \n",
    "xTrain= np.array([[5,6]])\n",
    "b=yTrIon\n",
    "yTrain = np.array([1])\n",
    "w=xTrIon\n",
    "M=20\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick_forest)\n",
    "print('Note: there is strong delay between points')\n",
    "plt.title('Use shift-click to add negative points.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6a43e7907e81937d92a9e0a9295ba8f4",
     "grade": false,
     "grade_id": "cell-faa99e3970c2080c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h2>Boosting</h2>\n",
    "\n",
    "<p>Another option to improve your decision trees is to build trees of small depth (e.g. only depth=3 or depth=4). These do not have high variance, but instead suffer from <b>high bias</b>. You can reduce the bias of a classifier with boosting. Implement the function <code>boosttree</code>, which applies Adaboost on your <code>cart</code> functions. You should be able to use the function <code>evalforest</code> to evaluate your boosted ensemble (provdided you pass on the weights correctly.)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "030ca99b525c9574d0a137a03d2709f7",
     "grade": false,
     "grade_id": "cell-6e4bec6d93833b06",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def boosttree(x,y,maxiter=100,maxdepth=2):\n",
    "    \"\"\"Learns a boosted decision tree.\n",
    "    \n",
    "    Input:\n",
    "        x:        n x d matrix of data points\n",
    "        y:        n-dimensional vector of labels\n",
    "        maxiter:  maximum number of trees\n",
    "        maxdepth: maximum depth of a tree\n",
    "        \n",
    "    Output:\n",
    "        forest: list of TreeNode decision trees of length m\n",
    "        alphas: m-dimensional weight vector\n",
    "        \n",
    "    (note, m is at most maxiter, but may be smaller,\n",
    "    as dictated by the Adaboost algorithm)\n",
    "    \"\"\"\n",
    "    assert np.allclose(np.unique(y), np.array([-1,1])); # the labels must be -1 and 1 \n",
    "    n,d = x.shape\n",
    "    weights = np.ones(n) / n\n",
    "    preds   = None\n",
    "    forest  = []\n",
    "    alphas  = []\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return forest, alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "97e9c1a6842a511a06bad2c3a15eb3ef",
     "grade": false,
     "grade_id": "cell-d9cacc62ecaf87cb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<p>The following script evaluates the test and training error of a boosted forest as we increase the number of trees.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b77d7852105a15f0086c93e5c82a78a1",
     "grade": false,
     "grade_id": "cell-fde54aafd46b5993",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "M=20 # max number of trees\n",
    "alltrees,allalphas=boosttree(xTrIon,yTrIon,maxdepth=3,maxiter=M)\n",
    "\n",
    "err_trB=[]\n",
    "loss_trB=[]\n",
    "err_teB=[]\n",
    "for i in range(M):\n",
    "    trees=alltrees[:i+1]\n",
    "    alphas=allalphas[:i+1]\n",
    "    trErr = np.mean(np.sign(evalforest(trees,xTrIon,alphas)) != yTrIon)\n",
    "    trLoss =np.mean(np.exp(-evalforest(trees,xTrIon,alphas)*yTrIon))\n",
    "    teErr = np.mean(np.sign(evalforest(trees,xTeIon,alphas)) != yTeIon)\n",
    "    err_trB.append(trErr)\n",
    "    err_teB.append(teErr)\n",
    "    loss_trB.append(trLoss)\n",
    "    print(\"[%d] exp loss = %.4f training err = %.4f\\ttesting err = %.4f\" % (i,trLoss,trErr, teErr))\n",
    "\n",
    "plt.figure()\n",
    "line_tr, = plt.plot(range(M),err_trB,label=\"Training Error\")\n",
    "line_te, = plt.plot(range(M),err_teB,label=\"Testing error\")\n",
    "line_trloss,=plt.plot(range(M),loss_trB,label='Exp. Loss')\n",
    "plt.title(\"Adaboost\")\n",
    "plt.legend(handles=[line_tr, line_te,line_trloss])\n",
    "plt.xlabel(\"# of trees\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.show()\n",
    "# Your training error should converge very quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfc3894e56b5d974ac10da8c59350a5c",
     "grade": false,
     "grade_id": "cell-412235795894022a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "trees,alphas=boosttree(xTrSpiral,yTrSpiral,maxdepth=3,maxiter=20)\n",
    "visclassifier(lambda X:evalforest(trees,X,alphas),xTrSpiral,yTrSpiral)\n",
    "\n",
    "print(\"elapsed time: %.2f seconds\" % (t1-t0))\n",
    "print(\"Training error: %.4f\" % np.mean(np.sign(evalforest(trees,xTrSpiral)) != yTrSpiral))\n",
    "print(\"Testing error:  %.4f\" % np.mean(np.sign(evalforest(trees,xTeSpiral)) != yTeSpiral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8010201ed3fe0e17162a3c6796f8302",
     "grade": false,
     "grade_id": "cell-e53ca9e4cded1a68",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "xTrain= np.array([[5,6],[2,5]])\n",
    "yTrain = np.array([-1,1])\n",
    "fig = plt.figure()\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "\n",
    "\n",
    "def onclick_boost(event):\n",
    "    \"\"\"\n",
    "    Visualize boosting, including new point\n",
    "    \"\"\"\n",
    "    global xTrain,yTrain\n",
    "    # create position vector for new point\n",
    "    pos=np.array([[event.xdata,event.ydata]]) \n",
    "    if event.key == 'shift': # add positive point\n",
    "        color='or'\n",
    "        label=1\n",
    "    else: # add negative point\n",
    "        color='ob'\n",
    "        label=-1    \n",
    "    xTrain = np.concatenate((xTrain,pos), axis = 0)\n",
    "    yTrain = np.append(yTrain, label)\n",
    "    marker_symbols = ['o', 'x']\n",
    "    classvals = np.unique(yTrain)\n",
    "            \n",
    "    mycolors = [[0.5, 0.5, 1], [1, 0.5, 0.5]]\n",
    "    \n",
    "    # return 300 evenly spaced numbers over this interval\n",
    "    res=300\n",
    "    xrange = np.linspace(0,1,res)\n",
    "    yrange = np.linspace(0,1,res)\n",
    "    \n",
    "    # repeat this matrix 300 times for both axes\n",
    "    pixelX = repmat(xrange, res, 1)\n",
    "    pixelY = repmat(yrange, res, 1).T\n",
    "    xTe = np.array([pixelX.flatten(), pixelY.flatten()]).T\n",
    "    \n",
    "    # get forest\n",
    "    forest,alphas=boosttree(xTrain,yTrain,maxdepth=3,maxiter=5)\n",
    "    if len(forest) > 0:\n",
    "        fun = lambda X: evalforest(forest,X,alphas)\n",
    "        # test all of these points on the grid\n",
    "        testpreds = fun(xTe)\n",
    "\n",
    "        # reshape it back together to make our grid\n",
    "        Z = testpreds.reshape(res, res)\n",
    "        Z[0,0] = 1 # optional: scale the colors correctly\n",
    "\n",
    "        plt.cla()    \n",
    "        plt.xlim((0,1))\n",
    "        plt.ylim((0,1))\n",
    "        # fill in the contours for these predictions\n",
    "        plt.contourf(pixelX, pixelY, np.sign(Z), colors=mycolors)\n",
    "    \n",
    "    for idx, c in enumerate(classvals):\n",
    "        plt.scatter(xTrain[yTrain == c,0],\n",
    "            xTrain[yTrain == c,1],\n",
    "            marker=marker_symbols[idx],\n",
    "            color='k'\n",
    "            )\n",
    "    plt.show()\n",
    "    \n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick_boost)\n",
    "plt.title('Use shift-click to add negative points.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63af15f235e1b3d1179963b35c921d1f",
     "grade": true,
     "grade_id": "sqsplit_test2",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34665a8af986226526b5dd403ccff096",
     "grade": true,
     "grade_id": "sqsplit_test3",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "024f50a47794c430bff122924bc1a9ef",
     "grade": true,
     "grade_id": "cart_test1",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38a6065fd55277bb545877d9abf8b139",
     "grade": true,
     "grade_id": "cart_test2",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84fe11e5d6c1ed7a5e3bfe04b0bd1b15",
     "grade": true,
     "grade_id": "cart_test3",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e95d41362e8d6b93547eee767479b3cc",
     "grade": true,
     "grade_id": "evaltree_test1",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "308ad5e0000c90f1c311b348e62e87a0",
     "grade": true,
     "grade_id": "evaltree_test2",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ca14bce7cba6fe1ef59b538b2d9de59",
     "grade": true,
     "grade_id": "forest_test1",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c9224cd54ea67257ebcece7b4d986e9",
     "grade": true,
     "grade_id": "bagging_test1",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e44aea69ea09a10cb1459f995faf0388",
     "grade": true,
     "grade_id": "bagging_test2",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1febcf0c4ce13cc526c49f818348426f",
     "grade": true,
     "grade_id": "boosting_test1",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "48206f2fa4480b0a604e89905866620d",
     "grade": false,
     "grade_id": "cell-48581b14a6981e50",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Competition**: we ask you to improve the speed of evaltree and cart while keeping both functions accurate.\n",
    "    \n",
    "You will receive 3 points if your implemention as fast or faster than our slow solution on hidden data and 3 points if your implementation as fast or faster than our quick solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e4115605a6b52f8af272d76da1611f73",
     "grade": false,
     "grade_id": "cell-618211b2d58e4ea7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def evaltreecomp(root,xTe,idx=[]):\n",
    "    \"\"\"Evaluates xTe using decision tree root. Same as evaltree but designed to be as efficient as possible.\n",
    "    \n",
    "    Input:\n",
    "        root: TreeNode decision tree\n",
    "        xTe:  n x d matrix of data points\n",
    "        idx:  choosen indices, optional argument that might be helpful with implementation strategy\n",
    "    Output:\n",
    "        pred: n-dimensional vector of predictions\n",
    "    \"\"\"\n",
    "    assert root is not None\n",
    "    n = xTe.shape[0]\n",
    "    pred = np.zeros(n)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return pred\n",
    "\n",
    "def cartcomp(xTr,yTr,depth=np.inf,weights=None):\n",
    "    \"\"\"Builds a CART tree. Same as cart but designed to be as efficient as possible.\n",
    "    \n",
    "    The maximum tree depth is defined by \"maxdepth\" (maxdepth=2 means one split).\n",
    "    Each example can be weighted with \"weights\".\n",
    "\n",
    "    Args:\n",
    "        xTr:      n x d matrix of data\n",
    "        yTr:      n-dimensional vector\n",
    "        maxdepth: maximum tree depth\n",
    "        weights:  n-dimensional weight vector for data points\n",
    "\n",
    "    Returns:\n",
    "        tree: root of decision tree\n",
    "    \"\"\"\n",
    "    n,d = xTr.shape\n",
    "    if weights is None:\n",
    "        w = np.ones(n) / float(n)\n",
    "    else:\n",
    "        w = weights\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f683347acad34321e87cdda462a0536",
     "grade": false,
     "grade_id": "cell-25f260c3b553b9db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "root = cartcomp(xTrIon, yTrIon)\n",
    "t1 = time.time()\n",
    "\n",
    "repeat_factor = 20000\n",
    "xTeIonRepeated = np.repeat(xTeIon, repeat_factor, axis = 0)\n",
    "\n",
    "t2 = time.time()\n",
    "pred = evaltreecomp(root,xTeIonRepeated)\n",
    "t3 = time.time()\n",
    "\n",
    "\n",
    "print(\"elapsed time for cartcomp: %.2f seconds\" % (t1-t0))\n",
    "print(\"elapsed time for evaltreecomp: %.2f seconds\" % (t3-t2))\n",
    "print(\"combined time: %.2f seconds \\n\" % ((t1-t0)+(t3-t2)))\n",
    "print(\"The approximate _combined_ times (i.e., for running both cartcomp() and evaltreecomp()) you should beat are:\")\n",
    "print(\"slow time: ~1.8s\")\n",
    "print(\"fast time: ~4.8s\")\n",
    "print(\"NOTE 1: your time may be different as other people may be running on the server!\")\n",
    "print(\"NOTE 2: Your competition code must pass the hidden correctness tests too! Make sure you test your code!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a217b663ea3cf000bb2b91eff482bbfc",
     "grade": true,
     "grade_id": "competition_test1",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eef3534f2cb7263a05d7acf921a3eee8",
     "grade": true,
     "grade_id": "competition_test2",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
